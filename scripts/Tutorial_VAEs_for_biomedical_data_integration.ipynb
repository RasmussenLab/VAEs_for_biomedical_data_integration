{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FUjdkp5dCNTj"
      },
      "source": [
        "\n",
        "\n",
        "# ON THE USE OF VAES FOR BIOMEDICAL DATA INTEGRATION: THE TUTORIAL\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dpU4esWJDMK3"
      },
      "source": [
        "## Intro\n",
        "\n",
        "Hi!\n",
        "This notebook is a short tutorial to guide you through the main findings of the paper.\n",
        "\n",
        "> ðŸ’» **Optional GPU acceleration:**\n",
        ">\n",
        "> We can use GPUs when running colab notebooks! Go to the top right corner and click on the arrow pointing downwards ðŸ”½. There you can choose to ``` Change runtime type``` and select the ```Hardware accelerator``` to be ```T4```.\n",
        ">\n",
        "\n",
        "**Background**\n",
        "\n",
        "We will explore the behavior of Multimodal Variational Autoencoders (VAEs) when integrating diverse data modalities.\n",
        "\n",
        ">ðŸ“• **What are VAEs?**\n",
        ">\n",
        ">If you are not familiar with VAEs, you can read:\n",
        ">- _The original paper_: [Autoencoding Variational Bayes](https://arxiv.org/abs/1312.6114), by Diederik P. Kingma and Max Welling.\n",
        ">  - Strong theoretical foundation, motivation of the Evidence Lower Bound Objective (ELBO).\n",
        ">- _The MultiOmics Variational Autoencoder paper_ [MOVE](https://www.nature.com/articles/s41587-022-01520-x).\n",
        ">\n",
        ">  - Presents the MultiOmics Variational autoEncoder (MOVE) and applies it to a cohort of Type II diabetes (T2D) patients.\n",
        ">\n",
        ">- _Deep Generative Modelling_, by Jakub M. Tomczak. Chapter 4.3.\n",
        ">  \n",
        ">  - Solid theoretical motivation with code examples.\n",
        "\n",
        "\n",
        "\n",
        "**The notebook**\n",
        "\n",
        "In this notebook we will:\n",
        "- Install the Multiomics Variational Autoencoder [MOVE](https://www.nature.com/articles/s41587-022-01520-x)\n",
        "- Generate a synthetic dataset containing categorical and continuous features.\n",
        "- Run the main tasks in the MOVE pipeline:\n",
        "  - Encode the data\n",
        "  - Analyze the latent space\n",
        "  - Identify associations\n",
        "  - Visualize the perturbations\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Let's start!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qoTku0mwFXcZ"
      },
      "source": [
        "## Install and import the required packages\n",
        "\n",
        "The code to create and run the Multiomics Variational AutoEncoder (MOVE) can be installed as a pip package.\n",
        "\n",
        ">âš ï¸ **Warning**\n",
        ">\n",
        ">You'll be asked to restart the runtime after running the command below to update the changes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9XKoX_2v_1vS",
        "outputId": "60ed98c1-e87d-425c-d671-d13bc3cc54a9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: move-dl in /usr/local/lib/python3.10/dist-packages (1.5.0)\n",
            "Requirement already satisfied: hydra-core in /usr/local/lib/python3.10/dist-packages (from move-dl) (1.3.2)\n",
            "Requirement already satisfied: numpy<2 in /usr/local/lib/python3.10/dist-packages (from move-dl) (1.26.4)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from move-dl) (2.2.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from move-dl) (2.4.1+cu121)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from move-dl) (3.7.1)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.10/dist-packages (from move-dl) (0.13.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from move-dl) (1.5.2)\n",
            "Requirement already satisfied: scipy>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from move-dl) (1.13.1)\n",
            "Requirement already satisfied: omegaconf<2.4,>=2.2 in /usr/local/lib/python3.10/dist-packages (from hydra-core->move-dl) (2.3.0)\n",
            "Requirement already satisfied: antlr4-python3-runtime==4.9.* in /usr/local/lib/python3.10/dist-packages (from hydra-core->move-dl) (4.9.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from hydra-core->move-dl) (24.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->move-dl) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->move-dl) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->move-dl) (4.54.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->move-dl) (1.4.7)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->move-dl) (10.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->move-dl) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->move-dl) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->move-dl) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->move-dl) (2024.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->move-dl) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->move-dl) (3.5.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->move-dl) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->move-dl) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->move-dl) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->move-dl) (3.4.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->move-dl) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->move-dl) (2024.6.1)\n",
            "Requirement already satisfied: PyYAML>=5.1.0 in /usr/local/lib/python3.10/dist-packages (from omegaconf<2.4,>=2.2->hydra-core->move-dl) (6.0.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->move-dl) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->move-dl) (3.0.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->move-dl) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "! pip install move-dl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8iHdt0HbJI1B"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import random as rnd\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "import shutil\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "from sklearn.datasets import make_sparse_spd_matrix\n",
        "from PIL import Image\n",
        "from matplotlib.pyplot import cm\n",
        "import seaborn as sns\n",
        "from matplotlib.colors import ListedColormap\n",
        "from IPython.display import display\n",
        "from IPython.display import Image as Image_display\n",
        "import torch\n",
        "\n",
        "#from scipy.stats import pearsonr\n",
        "#from move.data.preprocessing import scale\n",
        "#import os\n",
        "#import io\n",
        "#import seaborn as sns\n",
        "#import sys\n",
        "#import matplotlib as mpl\n",
        "#from itertools import chain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_BHL59yYC13q"
      },
      "outputs": [],
      "source": [
        "CUDA = \"true\" if torch.cuda.is_available() else \"false\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X33ym7PUDWMJ"
      },
      "source": [
        "## Generating a synthetic dataset\n",
        "\n",
        "We will now create a synthetic dataset by drawing a number of samples ($N_{samples}$, in rows) from a known distribution that describes a number of properties or features of the samples ($N_{features}$, in columns). We will create a multimodal dataset as a combination of 4 modalities: Categorical_A and Categorical_B, with one feature each, and Continuous_A and Continuous_B with 10 features each.\n",
        "\n",
        ">**ðŸ“• Theoretical insights:** In our synthetic datasets, each sample was originally obtained as a measurement or draw from a multivariate gaussian distribution, ð’™ âˆ¼ ð’©(ðœ‡, ðœŽ), where each feature was described by one of the components of the gaussian. This relatively simple protocol enabled us to simulate different scales of possible feature values via the mean of each feature. It also allowed us to add an arbitrary number of linear associations between features by controlling the covariance matrix describing the distribution. A vector encoding the means of each feature or column and a sparse covariance matrix (sparsity defined by $Î±_{cov}$ = 0.99) were used to define the parameters of the multivariate random normal distribution. The dataset went subsequently through the standard preprocessing for continuous variables, which consisted in $\\log_2(1+x)$ transformation and posterior normalization to zero mean and unit variance.\n",
        ">\n",
        ">Stronger correlations could  subsequently be added by defining the second half of features to be linear combinations of randomly chosen features in the first half:\n",
        ">\n",
        ">$$Feature_k=\\frac{Feature_i + Feature_j}{2} + \\epsilon$$\n",
        ">\n",
        ">Where   was drawn from a univariate random normal distribution. $i$ and $j$ are features from the first half with $i$  $j$ , overriding a feature from the second half k.  Finally, continuous features could be turned into binary features by setting to zero/one all values below/above the mean. Ground truth associated variables were defined to be two variables with a correlation above a predefined threshold.\n",
        ">\n",
        "> In this tutorial, we will add the extra correlations.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JavLlueADdg6"
      },
      "outputs": [],
      "source": [
        "################################ Functions ####################################\n",
        "\n",
        "def get_feature_names(settings):\n",
        "    \"\"\"\n",
        "    This function returns a list with all feature names\n",
        "\n",
        "    Args:\n",
        "        settings (dict): dictionary with all settings\n",
        "\n",
        "    Returns:\n",
        "        all_feature_names: list with all feature names\n",
        "    \"\"\"\n",
        "    all_feature_names = [\n",
        "        f\"{key}_{i+1}\"\n",
        "        for key in settings.keys()\n",
        "        for i in range(settings[key][\"features\"])\n",
        "    ]\n",
        "    return all_feature_names\n",
        "\n",
        "\n",
        "def create_mean_profiles(settings):\n",
        "    \"\"\"\n",
        "    This function returns a list with all feature means.\n",
        "\n",
        "    Args:\n",
        "        settings (dict): dictionary with all settings.\n",
        "\n",
        "    Returns:\n",
        "        feature_means: list with all feature means.\n",
        "    \"\"\"\n",
        "    feature_means = []\n",
        "    for key in settings.keys():\n",
        "        mean = settings[key][\"offset\"]\n",
        "        for freq, coef in zip(\n",
        "            settings[key][\"frequencies\"], settings[key][\"coefficients\"]\n",
        "        ):\n",
        "            mean += coef * (\n",
        "                np.sin(\n",
        "                    freq * np.arange(settings[key][\"features\"]) + settings[key][\"phase\"]\n",
        "                )\n",
        "                + 1\n",
        "            )\n",
        "        feature_means.extend(list(mean))\n",
        "    return feature_means\n",
        "\n",
        "\n",
        "def create_ground_truth_correlations_file(correlations, COR_THRES):\n",
        "    \"\"\"\n",
        "    This function saves the ground truth associations in a Dataframe, which will be\n",
        "    then stored in a tsv file. Ground truth associations are defined to be the\n",
        "    pairs of fatures with a pearson correlation above COR_THRES.\n",
        "\n",
        "    Args:\n",
        "        correlations (np.array): array with all correlations.\n",
        "        COR_THRES (float): threshold for the pearson correlation.\n",
        "\n",
        "    Returns:\n",
        "        associations (pd.DataFrame): dataframe with all associations.\n",
        "    \"\"\"\n",
        "\n",
        "    sort_ids = np.argsort(abs(correlations), axis=None)[::-1]  # 1D: N x C\n",
        "    corr = np.take(correlations, sort_ids)  # 1D: N x C\n",
        "    sig_ids = sort_ids[abs(corr) > COR_THRES]\n",
        "    sig_ids = np.vstack(\n",
        "        (sig_ids // len(all_feature_names), sig_ids % len(all_feature_names))\n",
        "    ).T\n",
        "    associations = pd.DataFrame(sig_ids, columns=[\"feature_a_id\", \"feature_b_id\"])\n",
        "    a_df = pd.DataFrame(dict(feature_a_name=all_feature_names))\n",
        "    a_df.index.name = \"feature_a_id\"\n",
        "    a_df.reset_index(inplace=True)\n",
        "    b_df = pd.DataFrame(dict(feature_b_name=all_feature_names))\n",
        "    b_df.index.name = \"feature_b_id\"\n",
        "    b_df.reset_index(inplace=True)\n",
        "    associations = associations.merge(a_df, on=\"feature_a_id\", how=\"left\").merge(\n",
        "        b_df, on=\"feature_b_id\", how=\"left\"\n",
        "    )\n",
        "    associations[\"Correlation\"] = corr[abs(corr) > COR_THRES]\n",
        "    associations = associations[\n",
        "        associations.feature_a_id > associations.feature_b_id\n",
        "    ]  # Only one half of the matrix\n",
        "    return associations\n",
        "\n",
        "\n",
        "def plot_score_matrix(\n",
        "    array, feature_names, cmap=\"bwr\", vmin=None, vmax=None, label_step=5\n",
        "):\n",
        "    \"\"\"\n",
        "    This function plots a score matrix.\n",
        "\n",
        "    Args:\n",
        "        array (np.array): array with all correlations.\n",
        "        feature_names (list): list with all feature names.\n",
        "\n",
        "    Returns:\n",
        "        fig: fig object to save or show the plot.\n",
        "    \"\"\"\n",
        "    if vmin is None:\n",
        "        vmin = np.min(array)\n",
        "    elif vmax is None:\n",
        "        vmax = np.max(array)\n",
        "    # if ax is None:\n",
        "    fig = plt.figure(figsize=(5, 5))\n",
        "    plt.imshow(array, cmap=cmap, vmin=vmin, vmax=vmax)\n",
        "    plt.xticks(\n",
        "        np.arange(0, len(feature_names), label_step),\n",
        "        feature_names[::label_step],\n",
        "        fontsize=8,\n",
        "        rotation=90,\n",
        "    )\n",
        "    plt.yticks(\n",
        "        np.arange(0, len(feature_names), label_step),\n",
        "        feature_names[::label_step],\n",
        "        fontsize=8,\n",
        "    )\n",
        "    plt.tight_layout()\n",
        "    # ax\n",
        "    return fig\n",
        "\n",
        "def save_splitted_datasets(\n",
        "    settings: dict, PROJECT_NAME, dataset, all_feature_names, n_samples, outpath\n",
        "):\n",
        "    \"\"\"\n",
        "    This function saves the splitted datasets in tsv files.\n",
        "\n",
        "    \"\"\"\n",
        "    # Save index file\n",
        "    index = pd.DataFrame({\"ID\": list(np.arange(1, n_samples + 1))})\n",
        "    index.to_csv(outpath / f\"random.{PROJECT_NAME}.ids.txt\", index=False, header=False)\n",
        "    # Save continuous files\n",
        "    df = pd.DataFrame(\n",
        "        dataset, columns=all_feature_names, index=list(np.arange(1, n_samples + 1))\n",
        "    )\n",
        "    cum_feat = 0\n",
        "    for key in settings.keys():\n",
        "        df_feat = settings[key][\"features\"]\n",
        "        df_cont = df.iloc[:, cum_feat : cum_feat + df_feat]\n",
        "        df_cont.insert(0, \"ID\", np.arange(1, n_samples + 1))\n",
        "        df_cont.to_csv(\n",
        "            outpath / f\"random.{PROJECT_NAME}.{key}.tsv\", sep=\"\\t\", index=False\n",
        "        )\n",
        "        cum_feat += df_feat"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qf-hC7ckJBWR"
      },
      "source": [
        "**Hyperparameters**\n",
        "\n",
        "We will set the value of a number of hyperparameters to create and store the datasets. The values inside SETTINGS just define the sample-specific profiles."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "anw9f1V4E8SA"
      },
      "outputs": [],
      "source": [
        "########################### Hyperparameters ####################################\n",
        "PROJECT_NAME = \"random_all_sim\"\n",
        "HIGH_CORR = True # Add extra correlations as linear combinations of existing features\n",
        "SEED_1 = 1234 # Keeping the seed for reproducibility\n",
        "np.random.seed(SEED_1) # Setting seed values\n",
        "rnd.seed(SEED_1) # Setting seed values\n",
        "COV_ALPHA = 0.97 # Alpha: hyperparam governing the sparsity of the covariance matrix\n",
        "N_SAMPLES = 1000 # LOW N: 50, High N: 1000\n",
        "\n",
        "# Settings: Dictionary with names and values to create feature profiles.\n",
        "SETTINGS = {\n",
        "    \"Continuous_A\": {\n",
        "        \"features\": 10,\n",
        "        \"frequencies\": [0.002, 0.01, 0.02],\n",
        "        \"coefficients\": [500, 100, 50],\n",
        "        \"phase\": 0,\n",
        "        \"offset\": 500,\n",
        "    },\n",
        "    \"Continuous_B\": {\n",
        "        \"features\": 10,\n",
        "        \"frequencies\": [0.001, 0.05, 0.08],\n",
        "        \"coefficients\": [80, 20, 10],\n",
        "        \"phase\": np.pi / 2,\n",
        "        \"offset\": 400,\n",
        "    },\n",
        "    \"Categorical_A\": {\n",
        "        \"features\": 1,\n",
        "        \"frequencies\": [0.1, 0.5, 0.8],\n",
        "        \"coefficients\": [.2, .1, .05],\n",
        "        \"phase\": np.pi / 2,\n",
        "        \"offset\": 10,\n",
        "    },\n",
        "        \"Categorical_B\": {\n",
        "        \"features\": 1,\n",
        "        \"frequencies\": [0.01, 0.5, 0.08],\n",
        "        \"coefficients\": [10, .1, .05],\n",
        "        \"phase\": np.pi,\n",
        "        \"offset\": 1,\n",
        "    }\n",
        "}\n",
        "\n",
        "COR_THRES = 0.02 # Correlation threshold above which a pair of features is considered to be associated\n",
        "PAIRS_OF_INTEREST = [(1,2),(3,4)]\n",
        "\n",
        "\n",
        "# Path to store output files\n",
        "outpath = Path(\"./synthetic_data_II\")\n",
        "outpath.mkdir(exist_ok=True, parents=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kAs8RiUMI-5C"
      },
      "source": [
        "**Script**\n",
        "\n",
        "We will now create the different datasets and save them in a number of tables, as tsv files. In addition, a file with samples ids will be created."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CVHFlu9YI_Mo"
      },
      "outputs": [],
      "source": [
        "###################### Script to create a synthetic dataset ####################\n",
        "\n",
        "# Add all datasets in a single matrix:\n",
        "all_feature_names = get_feature_names(SETTINGS)\n",
        "feat_means = create_mean_profiles(SETTINGS)\n",
        "\n",
        "# Covariance matrix\n",
        "covariance_matrix = make_sparse_spd_matrix(dim=len(all_feature_names), alpha=COV_ALPHA, norm_diag=True,random_state=SEED_1)\n",
        "ABS_MAX = np.max(abs(covariance_matrix))\n",
        "\n",
        "# No scaling in the dataset creation! It will be handled in preprocessing.\n",
        "scaled_dataset = np.random.multivariate_normal(feat_means, covariance_matrix, N_SAMPLES)\n",
        "\n",
        "# Add extra correlations as linear combinations of existing features\n",
        "if HIGH_CORR: # The last half of the features are combinations of the first half:\n",
        "    for i in range(scaled_dataset.shape[1]//2):\n",
        "        col_1 = np.random.choice(range(scaled_dataset.shape[1]//2))\n",
        "        col_2 = np.random.choice(range(scaled_dataset.shape[1]//2))\n",
        "        scaled_dataset[:,i+scaled_dataset.shape[1]//2] = (scaled_dataset[:,col_1]+scaled_dataset[:,col_2])/2 + np.random.normal()\n",
        "\n",
        "# Binarize the categorical dataset\n",
        "NUM_CAT = SETTINGS[\"Categorical_A\"][\"features\"] + SETTINGS[\"Categorical_B\"][\"features\"]\n",
        "columns_to_binarize = scaled_dataset[:,-NUM_CAT:]\n",
        "\n",
        "# Compute the mean of each of the categorical columns\n",
        "means = columns_to_binarize.mean(axis=0)\n",
        "\n",
        "# Apply the binarization\n",
        "scaled_dataset[:,-NUM_CAT:] = (columns_to_binarize > means).astype(int)\n",
        "\n",
        "# Plot correlations matrix\n",
        "correlations = np.corrcoef(scaled_dataset, rowvar=False)\n",
        "fig = plot_score_matrix(correlations, all_feature_names, vmin=-1, vmax=1, label_step=5)\n",
        "plt.title(\"Correlations between variables\")\n",
        "fig.savefig(outpath / f\"Correlations_{PROJECT_NAME}.png\", dpi=200)\n",
        "\n",
        "# Sort correlations by absolute value\n",
        "associations = create_ground_truth_correlations_file(correlations, COR_THRES)\n",
        "associations.to_csv(outpath / f\"changes.{PROJECT_NAME}.txt\", sep=\"\\t\", index=False)\n",
        "\n",
        "# Write tsv files with feature values for all samples in both datasets:\n",
        "save_splitted_datasets(\n",
        "    SETTINGS, PROJECT_NAME, scaled_dataset, all_feature_names, N_SAMPLES, outpath\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nKBr1VfPMD3L"
      },
      "source": [
        "You can have a look at the created datasets at:\n",
        "\n",
        "```\n",
        "./content/synthetic_data_II/\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LpI0CjhjDBpf"
      },
      "source": [
        "## Running MOVE\n",
        "\n",
        "When running MOVE, we read a number of hyperparameters from the configuration (.yaml) files. We will create these configuration files now.\n",
        "\n",
        "> **For the advanced reader:**\n",
        ">\n",
        ">Feel free to modify the hyperparameters! In particular, you can play with the strength on the KLD with the prior ($\\beta$) or the weight assigned to the loss associated to each dataset (weight parameter on the data yaml config).\n",
        "> Particular hyperparameters will shape the behavior of the modls and therefore results, as we show in the manuscript!\n",
        ">\n",
        "\n",
        "\n",
        "### Create config files:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bc9RmZZVOGG_"
      },
      "outputs": [],
      "source": [
        "config_paths = [Path(\"./config/data/\"),\n",
        "                Path(\"./config/task/\")]\n",
        "\n",
        "for config_path in config_paths:\n",
        "  config_path.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "data_yaml_contents = {\n",
        "\"random_continuous_paper_II.yaml\": \"\"\"\n",
        "# DO NOT EDIT DEFAULTS\n",
        "defaults:\n",
        "  - base_data\n",
        "\n",
        "# FEEL FREE TO EDIT BELOW\n",
        "\n",
        "raw_data_path: synthetic_data_II/              # where raw data is stored\n",
        "interim_data_path: interim_data_cont_paper_II/  # where intermediate files will be stored\n",
        "results_path: results_cont_paper_II/     # where result files will be placed\n",
        "\n",
        "sample_names: random.random_all_sim.ids  # names/IDs of each sample, must appear in the\n",
        "                                # other datasets\n",
        "\n",
        "categorical_inputs:\n",
        "  - name: random.random_all_sim.Categorical_A\n",
        "  - name: random.random_all_sim.Categorical_B\n",
        "\n",
        "continuous_inputs:   # a list of continuous datasets\n",
        "  - name: random.random_all_sim.Continuous_A\n",
        "    weight: 1\n",
        "    log2: true\n",
        "    scale: true\n",
        "  - name: random.random_all_sim.Continuous_B\n",
        "    weight: 1\n",
        "    log2: true\n",
        "    scale: true\n",
        "\"\"\"}\n",
        "\n",
        "task_yaml_contents = {\"random_continuous_paper_II__latent.yaml\": \"\"\"\n",
        "\n",
        "defaults:\n",
        "  - analyze_latent\n",
        "\n",
        "batch_size: 10\n",
        "\n",
        "feature_names:\n",
        "  - Continuous_A_1\n",
        "  - Continuous_B_1\n",
        "  - Continuous_B_2\n",
        "  - Continuous_B_3\n",
        "  - Continuous_B_4\n",
        "  - Continuous_B_5\n",
        "  - Continuous_B_6\n",
        "  - Continuous_B_7\n",
        "  - Continuous_B_8\n",
        "  - Categorical_A_1\n",
        "\n",
        "model:\n",
        "  num_hidden:\n",
        "    - 15\n",
        "  num_latent: 3\n",
        "  beta: .0001\n",
        "\n",
        "training_loop:\n",
        "  lr: 1e-4\n",
        "  num_epochs: 300\n",
        "  batch_dilation_steps:\n",
        "    - 100\n",
        "    - 200\n",
        "  kld_warmup_steps:\n",
        "    - 50\n",
        "    - 100\n",
        "    - 125\n",
        "    - 150\n",
        "    - 175\n",
        "    - 200\n",
        "    - 225\n",
        "    - 250\n",
        "    - 275\n",
        "  early_stopping: false\n",
        "  patience: 0 \"\"\",\"\"\"random_continuous_paper_II__id_assoc_ks.yaml\"\"\": \"\"\"\n",
        "defaults:\n",
        "  - identify_associations_ks_schema\n",
        "\n",
        "batch_size: 10\n",
        "\n",
        "num_refits: 1\n",
        "sig_threshold: 0.05\n",
        "\n",
        "target_dataset: random.random_all_sim.Continuous_B\n",
        "target_value: plus_std\n",
        "save_refits: True\n",
        "\n",
        "model:\n",
        "  categorical_weights: ${weights:${data.categorical_inputs}}\n",
        "  continuous_weights: ${weights:${data.continuous_inputs}}\n",
        "  num_hidden:\n",
        "    - 15\n",
        "  num_latent: 3\n",
        "  beta: .0001\n",
        "  dropout: 0.1\n",
        "\n",
        "training_loop:\n",
        "  lr: 1e-4\n",
        "  num_epochs: 300\n",
        "  batch_dilation_steps:\n",
        "    - 100\n",
        "    - 200\n",
        "  kld_warmup_steps:\n",
        "    - 50\n",
        "    - 100\n",
        "    - 125\n",
        "    - 150\n",
        "    - 175\n",
        "    - 200\n",
        "    - 225\n",
        "    - 250\n",
        "    - 275\n",
        "  early_stopping: false\n",
        "  patience: 0\n",
        "\n",
        "perturbed_feature_names:\n",
        "  - Continuous_B_1\n",
        "target_feature_names:\n",
        "  - Continuous_B_1\n",
        "  - Continuous_B_2\n",
        "  - Continuous_B_3\n",
        "  - Continuous_B_4\n",
        "  - Continuous_B_5\n",
        "  - Continuous_B_6\n",
        "  - Continuous_B_7\n",
        "  - Continuous_B_8\n",
        "  - Continuous_B_9\n",
        "  - Continuous_B_10 \"\"\"}\n",
        "\n",
        "\n",
        "for file,content in data_yaml_contents.items():\n",
        "  with open(config_paths[0] / file, 'w') as f:\n",
        "      f.write(content)\n",
        "\n",
        "\n",
        "for file,content in task_yaml_contents.items():\n",
        "  with open(config_paths[1] / file, 'w') as f:\n",
        "      f.write(content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wI9WvXl4TSdz"
      },
      "source": [
        "You can have a look at the global config file:\n",
        "\n",
        "```\n",
        "./content/config/data/\n",
        "```\n",
        "\n",
        "And the task specific configuration files:\n",
        "```\n",
        "./content/config/data/\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S6ZvGAL1NMkj"
      },
      "source": [
        "### Performing the different tasks:\n",
        "\n",
        "Now we will:\n",
        "- Encode the data in a MOVE-friendly manner.\n",
        "- Train MOVE models according to the settings predefined in the configuration files.\n",
        "- Visualize a 2D representation of the latent space (UMAP).\n",
        "- Perform feature importance analyses with SHAP\n",
        "- Perturb the inputs to identify associated variables in the output.\n",
        "\n",
        "We will do it in command-line style, all at once, and we will discuss the results afterwards.\n",
        "\n",
        "\n",
        "> â° This step will take some minutes. Coffee break!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KwyFWar6DFIt",
        "outputId": "b709a133-d509-4230-f858-00a4bd78c051"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[INFO  - encode_data]: Beginning task: encode data\n",
            "[INFO  - encode_data]: Encoding 'random.random_all_sim.Categorical_A'\n",
            "[INFO  - encode_data]: Encoding 'random.random_all_sim.Categorical_B'\n",
            "[INFO  - encode_data]: Encoding 'random.random_all_sim.Continuous_A'\n",
            "[INFO  - encode_data]: Encoding 'random.random_all_sim.Continuous_B'\n",
            "[INFO  - analyze_latent]: Beginning task: analyze latent space\n",
            "[INFO  - analyze_latent]: Generating visualizations\n",
            "[INFO  - analyze_latent]: Projecting into latent space\n",
            "[INFO  - analyze_latent]: Reconstructing\n",
            "[INFO  - analyze_latent]: Computing reconstruction metrics\n",
            "[INFO  - analyze_latent]: Computing feature importance\n",
            "[INFO  - identify_associations]: Perturbing dataset: 'random.random_all_sim.Continuous_B'\n",
            "[INFO  - identify_associations]: Beginning task: identify associations continuous (ks)\n",
            "[INFO  - identify_associations]: Perturbation type: plus_std\n",
            "[INFO  - identify_associations]: Training models\n",
            "[INFO  - identify_associations]: Suggested absolute KS threshold is: 0.060736146190830516\n",
            "[INFO  - identify_associations]: Writing QC file\n",
            "[INFO  - identify_associations]: Significant hits found: 85\n",
            "[INFO  - identify_associations]: Writing results\n"
          ]
        }
      ],
      "source": [
        "### Running MOVE on simple synthetic data\n",
        "\n",
        "# Encode data\n",
        "! move-dl task=encode_data data=random_continuous_paper_II\n",
        "\n",
        "# Latent space analysis\n",
        "! move-dl task=random_continuous_paper_II__latent data=random_continuous_paper_II task.model.cuda={CUDA}\n",
        "\n",
        "# Identify assoc ks\n",
        "! move-dl task=random_continuous_paper_II__id_assoc_ks data=random_continuous_paper_II task.model.cuda={CUDA}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Azr_96MeDG6G"
      },
      "source": [
        "## Analyzing the results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "swFCMp79YpSQ"
      },
      "source": [
        "### Latent space analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xbeoNH_TRkxZ"
      },
      "outputs": [],
      "source": [
        "results_latent_path = Path(\"./results_cont_paper_II/latent_space/\")\n",
        "img = mpimg.imread(results_latent_path / 'reconstruction_metrics.png')\n",
        "imgplot = plt.imshow(img)\n",
        "plt.axis('off')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sJH5YrUrYo9x"
      },
      "outputs": [],
      "source": [
        "results_latent_path = Path(\"./results_cont_paper_II/latent_space/\")\n",
        "img = mpimg.imread(results_latent_path / 'loss_curve.png')\n",
        "imgplot = plt.imshow(img)\n",
        "plt.axis('off')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UKm_TeqUvAsS"
      },
      "source": [
        "**Loss curves:**\n",
        "\n",
        "The overall loss is a combination of Cross-Entropy for the categorical variables, SSE for continuous variables and a KLD term to enforce the sample distribution in latent space to be like our prior, a Normal Gaussian.\n",
        "\n",
        "Note:\n",
        "1. We are under a low regularization regime, KLD has no influence on the latent space distribution of samples.\n",
        "2. The model benefits a lot from reconstructing properly the categoical variables, seen as a Cross-Entropy loss going to zero."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "97tZFiQ1vz9P"
      },
      "outputs": [],
      "source": [
        "categorical_variable = \"Categorical_A_1\"\n",
        "continuous_variables = [\"Continuous_B_6\", \"Continuous_B_8\"]\n",
        "\n",
        "# Categorical variable:\n",
        "results_latent_path = Path(\"./results_cont_paper_II/latent_space/\")\n",
        "img = mpimg.imread(results_latent_path / f'latent_space_{categorical_variable}.png')\n",
        "imgplot = plt.imshow(img)\n",
        "plt.axis('off')\n",
        "plt.show()\n",
        "\n",
        "# Continuous variable I:\n",
        "results_latent_path = Path(\"./results_cont_paper_II/latent_space/\")\n",
        "img = mpimg.imread(results_latent_path / f'latent_space_{continuous_variables[0]}.png')\n",
        "imgplot = plt.imshow(img)\n",
        "plt.axis('off')\n",
        "plt.show()\n",
        "\n",
        "# Continuous variable II:\n",
        "results_latent_path = Path(\"./results_cont_paper_II/latent_space/\")\n",
        "img = mpimg.imread(results_latent_path / f'latent_space_{continuous_variables[1]}.png')\n",
        "imgplot = plt.imshow(img)\n",
        "plt.axis('off')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z5QYOlcAwsk7"
      },
      "source": [
        "**Latent space visualization:**\n",
        "\n",
        "This is a Umap representation of our 3D latent space.\n",
        "\n",
        "*Samples are ordered in clusters according to their categorical labels*\n",
        "\n",
        "We can already see that the network splits the latent space into clusters to perfectly classify the samples according to their categorical features. In this case, we have 2 categorical variables with two classes each, yielding 4 clasters with unique labels.\n",
        "\n",
        "*Samples are ordered following value gradients of learned continuous variables*\n",
        "\n",
        "Here the Umap representations provide a hint but do not help to illustrate this idea. We'll clearly see this behavior in the next section.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QWkBiX4NyKrV"
      },
      "outputs": [],
      "source": [
        "categorical_dataset = \"random.random_all_sim.Categorical_A\"\n",
        "continuous_dataset = \"random.random_all_sim.Continuous_B\"\n",
        "\n",
        "# Categorical variable:\n",
        "results_latent_path = Path(\"./results_cont_paper_II/latent_space/\")\n",
        "img = mpimg.imread(results_latent_path / f'feat_importance_{categorical_dataset}.png')\n",
        "imgplot = plt.imshow(img)\n",
        "plt.axis('off')\n",
        "plt.show()\n",
        "\n",
        "# Continuous variable:\n",
        "results_latent_path = Path(\"./results_cont_paper_II/latent_space/\")\n",
        "img = mpimg.imread(results_latent_path / f'feat_importance_{continuous_dataset}.png')\n",
        "imgplot = plt.imshow(img)\n",
        "plt.axis('off')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JgCLHqmazAK8"
      },
      "source": [
        "**Feature importance analysis: SHAP**\n",
        "\n",
        "The results obtained from SHAP analysis are a direct consequence of MOVE's way of organizing samples in latent space. Each dot in the plot corresponds to a sample, color coded by its label (top) for the categorical variable being shown, or its feature value of the continuous variable being shown. On the x axis we see the impact on latent space, which corresponds to the displacement of each sample when setting the value of the feature of interest to 0, sample by sample.\n",
        "\n",
        "Note that the most important features are learned, i.e. samples with similar values move similarly. In addition, samples move more when removing these features. At the bottom of the list we find variables that either varied faster, i.e. in shorter distances, or variables that the model ignored.\n",
        "\n",
        "\n",
        "> **ðŸ“• Theoretical insights:**\n",
        ">\n",
        ">An adaptation of the SHAP algorithm was used to define the importance that the model attributed to each input feature. The input dataset $X$, a matrix with $N_{samples}$ rows and $N_{features}$ columns, served as a reference and was encoded into its latent representation $z$, with $N_{samples}$ rows and $N_{latent}$ columns.  A perturbed dataset $Xâ€™$,  where the feature of interest had been substituted in all samples for the missing value (i.e. 0), was encoded into its latent representation $zâ€™$. The induced movement of the samples in latent space was then computed as the Euclidean distance $d$ between both encodings, i.e. $d = zâ€™ - z$. Finally, the overall movement of each sample was obtained by adding the movements in all latent components, as a sum of all elements in each row. This protocol was repeated for each feature, one by one, and the 10 features with the largest absolute sum difference across samples were taken to be the most important ones."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "va9TJIJzuRDy"
      },
      "source": [
        "### Visualizing the perturbations\n",
        "\n",
        "UMAP or t-SNE will inevitably distort and compress dimensions to ease visualization. However, if we compress the inputs to 3 latent dimensions, we can visualize the exact latent space, the exact movements induced in each sample after the perturbations, and hopefully get a clearer picture of what is actually going on!\n",
        "\n",
        "> ðŸ’µ **The price to pay**:\n",
        ">\n",
        "> It is not always possible to compress the inputs to only 3 dimensions. In the end it depends on many different factors as we commented in the first section of the manuscript: the sparsity of the features, their entanglement and the feature to sample ratio will play a role in defining how many latent dimensions are necessary to compress and reconstruct the inputs. It is also up to us to decide how noisy can the reconstructions be for downstream tasks."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y8SPVw1z5a6E"
      },
      "outputs": [],
      "source": [
        "def plot_3D_latent_and_displacement(\n",
        "    mu_baseline,\n",
        "    mu_perturbed,\n",
        "    feature_values,\n",
        "    feature_name,\n",
        "    show_baseline=True,\n",
        "    show_perturbed=True,\n",
        "    show_arrows=True,\n",
        "    step: int=1,\n",
        "    altitude: int=30,\n",
        "    azimuth: int=45,\n",
        "):\n",
        "    \"\"\"\n",
        "    Plot the movement of the samples in the 3D latent space after perturbing one\n",
        "    input variable.\n",
        "\n",
        "    Args:\n",
        "        mu_baseline:\n",
        "            ND array with dimensions n_samples x n_latent_nodes containing\n",
        "            the latent representation of each sample\n",
        "        mu_perturbed:\n",
        "            ND array with dimensions n_samples x n_latent_nodes containing\n",
        "            the latent representation of each sample after perturbing the input\n",
        "        feature_values:\n",
        "            1D array with feature values to map to a colormap (\"bwr\"). Each sample is\n",
        "            colored according to its value for the feature of interest.\n",
        "        feature_name:\n",
        "            name of the feature mapped to a colormap\n",
        "        show_baseline:\n",
        "            plot orginal location of the samples in the latent space\n",
        "        show_perturbed:\n",
        "            plot final location (after perturbation) of the samples in latent space\n",
        "        show_arrows:\n",
        "            plot arrows from original to final location of each sample\n",
        "        angle:\n",
        "            elevation from dim1-dim2 plane for the visualization of latent space.\n",
        "\n",
        "    Raises:\n",
        "        ValueError: If latent space is not 3-dimensional (3 hidden nodes).\n",
        "    Returns:\n",
        "        Figure\n",
        "    \"\"\"\n",
        "\n",
        "    my_cmap = sns.color_palette(\"RdYlBu\", as_cmap=True)\n",
        "\n",
        "    eps = 1e-16\n",
        "    if [np.shape(mu_baseline)[1], np.shape(mu_perturbed)[1]] != [3, 3]:\n",
        "        raise ValueError(\n",
        "            \" The latent space must be 3-dimensional. Redefine num_latent to 3.\"\n",
        "        )\n",
        "\n",
        "    fig = plt.figure(layout=\"constrained\", figsize=(6, 6))\n",
        "    ax = fig.add_subplot(projection=\"3d\")\n",
        "    ax.view_init(altitude, azimuth)\n",
        "\n",
        "    if show_baseline:\n",
        "        vmin, vmax = np.min(feature_values[::step]), np.max(feature_values[::step])\n",
        "        abs_max = np.max([abs(vmin), abs(vmax)])\n",
        "        ax.scatter(\n",
        "            mu_baseline[::step, 0],\n",
        "            mu_baseline[::step, 1],\n",
        "            mu_baseline[::step, 2],\n",
        "            marker=\"o\",\n",
        "            c=feature_values[::step],\n",
        "            s=15,\n",
        "            lw=0,\n",
        "            cmap=my_cmap,\n",
        "        )\n",
        "        ax.set_title(feature_name)\n",
        "\n",
        "    if show_perturbed:\n",
        "        ax.scatter(\n",
        "            mu_perturbed[::step, 0],\n",
        "            mu_perturbed[::step, 1],\n",
        "            mu_perturbed[::step, 2],\n",
        "            marker=\"o\",\n",
        "            c=feature_values[::step],\n",
        "            s=15,\n",
        "            label=\"perturbed\",\n",
        "            lw=0,\n",
        "        )\n",
        "    if show_arrows:\n",
        "        u = mu_perturbed[::step, 0] - mu_baseline[::step, 0]\n",
        "        v = mu_perturbed[::step, 1] - mu_baseline[::step, 1]\n",
        "        w = mu_perturbed[::step, 2] - mu_baseline[::step, 2]\n",
        "\n",
        "        module = np.sqrt(u * u + v * v + w * w)\n",
        "\n",
        "        mask = module > eps\n",
        "\n",
        "        max_u, max_v, max_w = np.max(abs(u)), np.max(abs(v)), np.max(abs(w))\n",
        "\n",
        "        # Arrow colors will be weighted contributions of red -> dim1, green -> dim2, and blue-> dim3. I.e. purple arrow means movement in dims 1 and 3\n",
        "        colors = [\n",
        "            (abs(du) / max_u, abs(dv) / max_v, abs(dw) / max_w, 0.7)\n",
        "            for du, dv, dw in zip(u, v, w)\n",
        "        ]\n",
        "        ax.quiver(\n",
        "            mu_baseline[::step, 0][mask],\n",
        "            mu_baseline[::step, 1][mask],\n",
        "            mu_baseline[::step, 2][mask],\n",
        "            u[mask],\n",
        "            v[mask],\n",
        "            w[mask],\n",
        "            color=colors,\n",
        "            lw=.8,\n",
        "            )\n",
        "    ax.set_xlabel(\"Dim 1\")\n",
        "    ax.set_ylabel(\"Dim 2\")\n",
        "    ax.set_zlabel(\"Dim 3\")\n",
        "\n",
        "\n",
        "    return fig"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m5NGBdcbuTdO"
      },
      "outputs": [],
      "source": [
        "! mkdir -p figures\n",
        "feature_list = [(\"Categorical_A\", 1),(\"Continuous_B\",8)]\n",
        "figure_path = Path(\"./figures/\")\n",
        "results_path = Path(\"./results/identify_associations/\")\n",
        "\n",
        "# Load latent space locations: Shape = (N_samples, N_latent, N_perturb +1)\n",
        "latent_space_location = np.load(\"./results_cont_paper_II/identify_associations/latent_location.npy\")\n",
        "latent_space_baseline = latent_space_location[:,:,-1]\n",
        "\n",
        "for (dataset, feature) in feature_list:\n",
        "    feature_values = pd.read_csv(f\"./synthetic_data_II/random.random_all_sim.{dataset}.tsv\", sep=\"\\t\")\n",
        "    feature_values = feature_values[dataset + '_' + str(feature)].values\n",
        "\n",
        "    # # Plot latent space:\n",
        "    pic_num = 0\n",
        "    n_pictures = 50\n",
        "\n",
        "    for azimuth, altitude in zip(\n",
        "        np.linspace(0, 60, n_pictures), np.linspace(15, 60, n_pictures)\n",
        "    ):\n",
        "\n",
        "        title = dataset + '_' + str(feature)\n",
        "\n",
        "        fig = plot_3D_latent_and_displacement(\n",
        "            latent_space_baseline,\n",
        "            latent_space_baseline,\n",
        "            feature_values=feature_values,\n",
        "            feature_name=f\"Sample movement\",\n",
        "            show_baseline=True,\n",
        "            show_perturbed=False,\n",
        "            show_arrows=False,\n",
        "            step=1,\n",
        "            altitude=altitude,\n",
        "            azimuth=azimuth,\n",
        "        )\n",
        "\n",
        "        fig.savefig(figure_path / f\"3D_latent_movement_{pic_num}_perturbed_feature.png\", dpi=50)\n",
        "        plt.close(fig)\n",
        "\n",
        "        if \"Continuous\" in dataset:\n",
        "            latent_space_perturbed = latent_space_location[:,:,feature-1]\n",
        "            fig = plot_3D_latent_and_displacement(\n",
        "                latent_space_baseline,\n",
        "                latent_space_perturbed,\n",
        "                feature_values=feature_values,\n",
        "                feature_name=f\"{title}\",\n",
        "                show_baseline=False,\n",
        "                show_perturbed=False,\n",
        "                show_arrows=True,\n",
        "                altitude=altitude,\n",
        "                azimuth=azimuth,\n",
        "            )\n",
        "            fig.savefig(figure_path / f\"3D_latent_movement_{pic_num}_arrows.png\", dpi=50)\n",
        "            plt.close(fig)\n",
        "\n",
        "        pic_num += 1\n",
        "\n",
        "\n",
        "    # Creating gifs\n",
        "    plot_types = [\"arrows\", \"perturbed_feature\"] if \"Continuous\" in dataset else [\"perturbed_feature\"]\n",
        "    for plot_type in plot_types:\n",
        "        frames = [\n",
        "            Image.open(figure_path / f\"3D_latent_movement_{pic_num}_{plot_type}.png\")\n",
        "            for pic_num in range(n_pictures)\n",
        "        ]  # sorted(glob.glob(\"*3D_latent*\"))]\n",
        "        frames[0].save(\n",
        "            figure_path / f\"{plot_type}_{title}.gif\",\n",
        "            format=\"GIF\",\n",
        "            append_images=frames[1:],\n",
        "            save_all=True,\n",
        "            duration=75,\n",
        "            loop=0,\n",
        "        )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i19TAgs7DISP"
      },
      "source": [
        "**Visualize gifs:**\n",
        "\n",
        "\n",
        "\n",
        "We started with multimodal samples, for which we simulated the measurement of 20 continuous features and 2 categorical features. Then we used MOVE to compress the representations of these samples to 3 dimensions in the network's latent layer. We will now visualize the real, complete 3D latent space.\n",
        "\n",
        "Here, each input sample is represented by a small sphere. Each sample's latent representation $z$ is a vector with three components, where each component corresponds to the value of a latent node.\n",
        "\n",
        "For example, sample 1 might have a latent vector $z = (\\text{Value of node 1},\\text{Value of node 2}, \\text{Value of node 3}) = (0.5,-5,-1)$. This sample would then be plotted at 0.5 for dimension 1, -5 for dimension 2, etc.\n",
        "\n",
        "\n",
        "We will plot:\n",
        "\n",
        "1) The latent space where each sample is color coded by the categorical label of Categorical_A_1, which has two possible classes.\n",
        "\n",
        "2) The latent space where each sample is color coded by the value of the continuous feature Continuous_B_8.\n",
        "\n",
        "3) The movement of each sample when adding a small perturbation (1 std) to the original value of Continuous_B_8"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wu7gmLaI--Ez"
      },
      "outputs": [],
      "source": [
        "# Path to your local GIF file\n",
        "gif_list = ['perturbed_feature_Categorical_A_1.gif', 'perturbed_feature_Continuous_B_8.gif','arrows_Continuous_B_8.gif' ]\n",
        "gif_path = 'figures/perturbed_feature_Categorical_A_1.gif'\n",
        "\n",
        "# Display the GIF\n",
        "\n",
        "for gif_path in gif_list:\n",
        "  display(Image_display(filename=\"figures/\" + gif_path))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w9ttU5N5CFRF"
      },
      "source": [
        "Here we can clearly see that:\n",
        "\n",
        "1. MOVE orders samples in clusters according to their categorical labels.\n",
        "2. MOVE orders samples in latent space following value gradients of learned continuous features.\n",
        "3. When performing perturbations on learned continuous variables, the latent representations of the samples move following the local value gradient of the perturbed feature. Of note, they do not necessarily all move in the same direction."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0asa40SkFl5-"
      },
      "source": [
        "# Final remarks: THE END!\n",
        "\n",
        "Thanks for going through the tutorial! We hope you found it useful.\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
